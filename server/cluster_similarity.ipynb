{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "232b98d9-30b7-448f-8237-8a87dfe423b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prpar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\prpar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "this file takes a dataframe of recall and event data and clusters them by company name\n",
    "\n",
    "refs\n",
    "- https://medium.com/dnb-data-science-hub/company-name-matching-6a6330710334\n",
    "- https://towardsdatascience.com/clustering-product-names-with-python-part-2-648cc54ca2ac/\n",
    "\n",
    "prereq:\n",
    "pip install scikit-learn nltk matplotlib cleanco levenshtein name_matching\n",
    "\"\"\"\n",
    "\n",
    "from get_data import get_dfs\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import unicodedata\n",
    "from cleanco import basename\n",
    "import time\n",
    "import Levenshtein\n",
    "from name_matching.name_matcher import NameMatcher\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeee0335-f825-43f8-8f6c-0aaf02eabe58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading table: recall....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prpar\\Documents\\OMSCS\\s25 - cse6242 dva\\CSE6242-Group-Project\\priya-streamlit-test\\get_data.py:34: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(f'select * from {table}', conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id cfres_id k_number pma_number  \\\n",
      "0  400cd411-6ba1-4360-9fea-b55e13468d00   212115     None       None   \n",
      "1  1d35718a-6bc8-4706-bd3d-31741cd98324   212318     None       None   \n",
      "2  224a2ab8-97ef-4799-879e-6083898ab2e7   211119     None       None   \n",
      "3  b264b469-7c7f-48d5-bea0-57f38377569a   208478     None       None   \n",
      "4  0aad8582-1a51-4374-998c-50cc0f4b4466   207500     None       None   \n",
      "\n",
      "  event_date_initiated event_date_created event_date_posted  \\\n",
      "0           2025-01-15               None        2025-02-05   \n",
      "1           2025-01-28               None        2025-02-03   \n",
      "2           2024-08-08               None        2024-12-03   \n",
      "3           2024-03-28               None        2024-07-01   \n",
      "4           2024-04-16               None        2024-05-30   \n",
      "\n",
      "  event_date_terminated     recall_status                   recalling_firm  \\\n",
      "0                  None  Open, Classified        Philips North America Llc   \n",
      "1                  None  Open, Classified          GE Medical Systems, LLC   \n",
      "2                  None  Open, Classified               Epilog Laser Corp.   \n",
      "3                  None  Open, Classified  Horiba Instruments Incorporated   \n",
      "4                  None  Open, Classified          Reflexion Medical, Inc.   \n",
      "\n",
      "   ... res_event_number                       root_cause_description  \\\n",
      "0  ...            96138                              Software design   \n",
      "1  ...            96208  Radiation Control for Health and Safety Act   \n",
      "2  ...            95757  Radiation Control for Health and Safety Act   \n",
      "3  ...            94839  Radiation Control for Health and Safety Act   \n",
      "4  ...            94533                              Software design   \n",
      "\n",
      "                                              action device_class  \\\n",
      "0  Philips began notifying consignees on about 01...            2   \n",
      "1  Firm sent an \"IMPORTANT ELECTRONIC PRODUCT RAD...            2   \n",
      "2  The measures to be taken to repair such defect...            N   \n",
      "3  Horiba plans to issue an IMPORTANT ELECTRONIC ...            N   \n",
      "4  On 04/29/2024, the firm sent an \"Urgent: Medic...            2   \n",
      "\n",
      "                                         device_name  \\\n",
      "0  Monitor, Physiological, Patient(With Arrhythmi...   \n",
      "1                          System, X-Ray, Stationary   \n",
      "2  Laser Marker Or Engraver, Industrial Or Commer...   \n",
      "3                            Spectroscopy Instrument   \n",
      "4  Fludeoxyglucose F18-Guided Radiation Therapy S...   \n",
      "\n",
      "  medical_specialty_description regulation_number  \\\n",
      "0                Cardiovascular          870.1025   \n",
      "1                     Radiology          892.1680   \n",
      "2                       Unknown              None   \n",
      "3                       Unknown              None   \n",
      "4                     Radiology          892.5060   \n",
      "\n",
      "                                          fei_number  \\\n",
      "0  [3006979678, 3021559257, 3009617712, 301359602...   \n",
      "1  [, 3001556265, 3009617712, 2243057, 3005116291...   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4                                       [3011716550]   \n",
      "\n",
      "                                    openfda_k_number  \\\n",
      "0  [K000854, K161056, K001433, K043551, K053207, ...   \n",
      "1  [K182517, K193637, K861994, K121854, K952871, ...   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4                                        [DEN220014]   \n",
      "\n",
      "                                 registration_number  \n",
      "0  [3006979678, 8030978, 3021559257, 3009617712, ...  \n",
      "1  [, 3001556265, 3009617712, 2243057, 3014403439...  \n",
      "2                                               None  \n",
      "3                                               None  \n",
      "4                                       [3011716550]  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "loading table: device_event....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prpar\\Documents\\OMSCS\\s25 - cse6242 dva\\CSE6242-Group-Project\\priya-streamlit-test\\get_data.py:34: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(f'select * from {table}', conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               event_id adverse_event_flag  \\\n",
      "0  137fc417-abd2-4c92-af98-f816d9d1b01c                  N   \n",
      "1  7d7e75df-69d0-4344-a609-d8294fcaf9e1                  N   \n",
      "2  b112bfb0-4306-498a-8ab9-76076641f4f9                  N   \n",
      "3  ea373448-a219-4494-9cb6-2b3fbb403c8f                  N   \n",
      "4  52eeaa61-643d-4452-aaa6-0b831af004c5                  N   \n",
      "\n",
      "  date_facility_aware date_manufacturer_received date_of_event date_received  \\\n",
      "0                None                 2024-01-22    2024-01-22    2024-02-12   \n",
      "1                None                 2024-01-18    2024-01-01    2024-02-12   \n",
      "2                None                 2023-12-22    2023-12-22    2024-01-19   \n",
      "3                None                 2024-01-24    2024-01-14    2024-02-12   \n",
      "4          2024-02-19                       None          None    2024-03-15   \n",
      "\n",
      "  date_report date_report_to_fda date_report_to_manufacturer  \\\n",
      "0  2024-02-12               None                        None   \n",
      "1  2024-03-13               None                        None   \n",
      "2  2024-03-19               None                        None   \n",
      "3  2024-02-12               None                        None   \n",
      "4  2024-02-19         2024-03-15                  2024-02-19   \n",
      "\n",
      "  device_date_of_manufacturer  ... report_date           report_number  \\\n",
      "0                  2020-03-01  ...        None   3013756811-2024-21297   \n",
      "1                  2013-08-17  ...        None      2028159-2024-00217   \n",
      "2                  2007-01-29  ...        None      2112667-2024-00415   \n",
      "3                        None  ...        None  3004753838-2024-035911   \n",
      "4                        None  ...  2024-03-15      6000034-2024-00965   \n",
      "\n",
      "    report_source_code report_to_fda report_to_manufacturer  \\\n",
      "0  Manufacturer report             Y                   None   \n",
      "1  Manufacturer report          None                   None   \n",
      "2  Manufacturer report             N                   None   \n",
      "3  Manufacturer report          None                   None   \n",
      "4   Distributor report             Y                   None   \n",
      "\n",
      "  reporter_occupation_code reprocessed_and_reused_flag single_use_flag  \\\n",
      "0                    OTHER                           N               N   \n",
      "1                      003                           N            None   \n",
      "2      BIOMEDICAL ENGINEER                           N               N   \n",
      "3                    OTHER                           N               Y   \n",
      "4                    OTHER                           N            None   \n",
      "\n",
      "                                     source_type  \\\n",
      "0                                     [Consumer]   \n",
      "1                                      [Foreign]   \n",
      "2  [Foreign, Health Professional, User facility]   \n",
      "3                                     [Consumer]   \n",
      "4                                             []   \n",
      "\n",
      "                   type_of_report  \n",
      "0            [Initial submission]  \n",
      "1  [Initial submission, Followup]  \n",
      "2  [Initial submission, Followup]  \n",
      "3            [Initial submission]  \n",
      "4            [Initial submission]  \n",
      "\n",
      "[5 rows x 78 columns]\n",
      "loading table: device....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prpar\\Documents\\OMSCS\\s25 - cse6242 dva\\CSE6242-Group-Project\\priya-streamlit-test\\get_data.py:34: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(f'select * from {table}', conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               event_id  \\\n",
      "0  137fc417-abd2-4c92-af98-f816d9d1b01c   \n",
      "1  137fc417-abd2-4c92-af98-f816d9d1b01c   \n",
      "2  7d7e75df-69d0-4344-a609-d8294fcaf9e1   \n",
      "3  7d7e75df-69d0-4344-a609-d8294fcaf9e1   \n",
      "4  b112bfb0-4306-498a-8ab9-76076641f4f9   \n",
      "\n",
      "                                          brand_name catalog_number  \\\n",
      "0  T:SLIM X2 INSULIN PUMP WITH INTEROPERABLE TECH...        1005011   \n",
      "1  T:SLIM X2 INSULIN PUMP WITH INTEROPERABLE TECH...        1005011   \n",
      "2                        CONSTELLATION VISION SYSTEM     8065751150   \n",
      "3                        CONSTELLATION VISION SYSTEM     8065751150   \n",
      "4                                       AESPIRE 7100           None   \n",
      "\n",
      "  date_received date_removed_flag date_returned_to_manufacturer  \\\n",
      "0    2024-02-12              None                          None   \n",
      "1    2024-02-12              None                          None   \n",
      "2    2024-02-12              None                          None   \n",
      "3    2024-02-12              None                          None   \n",
      "4    2024-01-19              None                          None   \n",
      "\n",
      "  device_age_text device_availability device_evaluated_by_manufacturer  \\\n",
      "0            None                 Yes                                R   \n",
      "1            None                 Yes                                R   \n",
      "2              DA                  No                                R   \n",
      "3              DA                  No                                R   \n",
      "4              DA                  No                                Y   \n",
      "\n",
      "                       device_event_key  ... manufacturer_d_city  \\\n",
      "0  137fc417-abd2-4c92-af98-f816d9d1b01c  ...           SAN DIEGO   \n",
      "1  137fc417-abd2-4c92-af98-f816d9d1b01c  ...           SAN DIEGO   \n",
      "2  7d7e75df-69d0-4344-a609-d8294fcaf9e1  ...              IRVINE   \n",
      "3  7d7e75df-69d0-4344-a609-d8294fcaf9e1  ...              IRVINE   \n",
      "4  b112bfb0-4306-498a-8ab9-76076641f4f9  ...            MADISON,   \n",
      "\n",
      "  manufacturer_d_country                             manufacturer_d_name  \\\n",
      "0                     US                            TANDEM DIABETES CARE   \n",
      "1                     US                            TANDEM DIABETES CARE   \n",
      "2                     US  ALCON RESEARCH, LLC - IRVINE TECHNOLOGY CENTER   \n",
      "3                     US  ALCON RESEARCH, LLC - IRVINE TECHNOLOGY CENTER   \n",
      "4                     US                              DATEX-OHMEDA, INC.   \n",
      "\n",
      "  manufacturer_d_postal_code manufacturer_d_state manufacturer_d_zip_code  \\\n",
      "0                      92130                   CA                   92130   \n",
      "1                      92130                   CA                   92130   \n",
      "2                      92618                   CA                   92618   \n",
      "3                      92618                   CA                   92618   \n",
      "4                      53718                   WI                   53718   \n",
      "\n",
      "  manufacturer_d_zip_code_ext model_number other_id_number udi_public  \n",
      "0                        None      1002717            None       None  \n",
      "1                        None      1002717            None       None  \n",
      "2                        None     TABLETOP            None       None  \n",
      "3                        None     TABLETOP            None       None  \n",
      "4                        None         None            None       None  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "----- elapsed time: 23.07004714012146 seconds -----\n"
     ]
    }
   ],
   "source": [
    "# read dfs\n",
    "df_recall, df_device_event, df_device = get_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9f1fdb02-8c01-4a0f-81e2-b51ffba87ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54520, 38)\n",
      "(100000, 78)\n",
      "(199943, 32)\n"
     ]
    }
   ],
   "source": [
    "print(df_recall.shape)\n",
    "print(df_device_event.shape)\n",
    "print(df_device.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef3fbf9-46f3-4130-85a3-0cae9336c5f7",
   "metadata": {},
   "source": [
    "## preprocess relevant columns\n",
    "\n",
    "From df_recall, we want to pull recalling_firm.\n",
    "From df_device, we want to pull manufacturer_d_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4cdccaaa-d0b0-4391-9cd3-4c1c19d51a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, col):\n",
    "    \"\"\"\n",
    "    0. replace Nan with empty string\n",
    "    1. lower\n",
    "    2. remove non-ascii chars\n",
    "    3. remove punctuation\n",
    "    4. remove common legal business strings (like 'corp')\n",
    "    \"\"\"\n",
    "    # remove NaN or None\n",
    "    df = df.fillna('')\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    def f(x):\n",
    "        x = x.lower() # step 1\n",
    "        x = unicodedata.normalize('NFKD', x).encode('ASCII', 'ignore').decode() # step 2\n",
    "        x = re.sub(r'[^\\w\\s]', '', x) # step 3\n",
    "        x = basename(x) # step 4\n",
    "        # word_tokens = word_tokenize(x) # step 5\n",
    "        # filtered_text = [word for word in x if word.lower() not in stop_words] # 5\n",
    "        # return ''.join(filtered_text) # 5\n",
    "        return x\n",
    "        \n",
    "    return df[col].apply(lambda x: f(x))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "613eeed0-3be2-4ec7-8811-2748085e6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recall['preproc_recalling_firm'] = preprocess(df_recall, 'recalling_firm')\n",
    "df_device['preproc_manufacturer_d_name'] = preprocess(df_device, 'manufacturer_d_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "88042eb4-a58a-4cbc-8e81-7d88f03ab7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4289\n"
     ]
    }
   ],
   "source": [
    "# now we need to combine recall and event device manufacturers into one list before vectorizing\n",
    "input_names = set(df_recall['preproc_recalling_firm'])\n",
    "input_names.update(df_device['preproc_manufacturer_d_name'])\n",
    "print(len(input_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f9e200a4-1d57-4794-8e9c-10255b4c5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(X, method='tfidf'):\n",
    "    \"\"\"\n",
    "    convert text data into numerical representations.\n",
    "    Possible methods:\n",
    "    - bag of words\n",
    "    - tf-idf\n",
    "    \"\"\"\n",
    "    if method == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(analyzer='word')\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(analyzer='word')\n",
    "    \n",
    "    vectorizer.fit(X)\n",
    "    return vectorizer.transform(X).toarray(), vectorizer # return vectorizer so it can be used later to assign cluster id to dfs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f75cdef-33ba-4372-82c7-3217ab04ea77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "39e6776d-ea72-49ae-bb9b-d4868cbebdb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4289, 5565)\n"
     ]
    }
   ],
   "source": [
    "X, vectorizer = vectorize_text(input_names)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf72130d-6e1d-4279-8b85-1d2028dd3bca",
   "metadata": {},
   "source": [
    "## cluster using kmeans\n",
    "General procedure:\n",
    "1. take all manufacturers from manufacturer_d_name to create cluster based on similarity \n",
    "2. add a col which assigns a \"label\" or \"cluster id\" to similar names\n",
    "3. apply cluster to manufacturers (recalling firms) in recall data\n",
    "4. join the dfs on this cluster id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d5c7fec1-f1c8-41a0-981f-422556f0acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(X, k=1000, random_state=52):\n",
    "    k = int(min(k, len(X) * 0.75))\n",
    "    print(f'n_clusters={k}')\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k, random_state=random_state)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    return clusters, kmeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c39a676a-70bb-4e0a-9d30-5c9eea88d021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters=1000\n",
      "------------ elapsed train time: 14.659651279449463 seconds -------------\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_device, kmeans = cluster(X)\n",
    "print(f'------------ elapsed train time: {time.time() - start} seconds -------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a078c3ba-8fa1-4547-ae68-29f537b7d2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b7253d-5b8f-41f3-b46c-58b80b0b1064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709010a4-b839-416e-a277-c72317ace571",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## WARNING : APPLYING K MEANS IS VERY TIME CONSUMING #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ecbcb-0db3-487f-9d8a-26bb2ace4255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply clustering to both datasets. first vectorize by the preprocessed col and predict\n",
    "def apply_cluster(x, vectorizer, kmeans):\n",
    "    x = vectorizer.transform([x]).toarray()\n",
    "    return kmeans.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a6317-4a5b-45ee-b136-95bc89cda84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### transform recall data ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b644da50-170d-42b6-b86b-6f1317f65d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# df_recall['cluster_id'] = df_recall['preproc_recalling_firm'].apply(lambda x: apply_cluster(x, vectorizer, kmeans))\n",
    "# print(f'------------ elapsed transform time: {time.time() - start} seconds -------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5db439-85a4-41c5-931a-c08dd277c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_recall['cluster_id'].value_counts())\n",
    "# df_recall[['cluster_id', 'recalling_firm', 'preproc_recalling_firm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8dd138-63d9-4942-b651-76120ddc4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### transform event device data ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f56933-e3d9-4f0e-9f48-0ca32b7626fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# df_device['cluster_id'] = df_device['preproc_manufacturer_d_name'].apply(lambda x: apply_cluster(x, vectorizer, kmeans))\n",
    "# print(f'------------ elapsed transform time: {time.time() - start} seconds -------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe76394-5dec-49e3-bd50-3ba49bdccc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_device['cluster_id'].value_counts())\n",
    "# df_device[['cluster_id', 'manufacturer_d_name', 'preproc_manufacturer_d_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce46d7-dd6f-4439-9d9f-638051ee2346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af88897-5091-4fbf-8af8-d40b9364265a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2587786f-a588-4072-bae9-4a383eb10e04",
   "metadata": {},
   "source": [
    "## cluster using distance metrics\n",
    "Use distance metrics to find similar matches between the two dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cd5ce-533e-4e5a-8360-be6350f756a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create method to join lists by fuzzy matching (lowest levenshtein distance)\n",
    "# def join_dfs_levenshtein(df1, df2, left_on, right_on, threshold, method='levenshtein'):\n",
    "#     \"\"\"\n",
    "#     joins two dfs based on distance between specified columns. apply threshold to be considered match.\n",
    "#     method options:\n",
    "#     - levenshtein\n",
    "#     - cosine similarity\n",
    "#     - jaccard similarity\n",
    "#     \"\"\"\n",
    "#     start = time.time()\n",
    "    \n",
    "#     # get unique values from each df\n",
    "#     df1_unique = set(df1[left_on])\n",
    "#     df2_unique = set(df2[right_on])\n",
    "\n",
    "#     # iterate to get most similar matches\n",
    "#     # merged_rows = []\n",
    "#     # for _, row1 in df1.iterrows():\n",
    "#     #     for _, row2 in df2.iterrows():\n",
    "#     #         if method == 'levenshtein':\n",
    "#     #             distance = Levenshtein.distance(str(row1[left_on]), str(row2[right_on]))\n",
    "#     #             if distance <= threshold:\n",
    "#     #                 merged_rows.append({**row1.to_dict(), **row2.to_dict(), 'levenshtein_distance': distance})\n",
    "\n",
    "                    \n",
    "#     print(f'------------ elapsed train time: {time.time() - start} seconds -------------')\n",
    "#     return pd.DataFrame(merged_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3284447e-1cb3-4782-9cbf-0e20855fdfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 10\n",
    "# merged_df = join_dfs_levenshtein(df_recall, df_device, 'preproc_recalling_firm', 'preproc_manufacturer_d_name', threshold)\n",
    "# print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d634f2f-bf17-47a6-8a53-5658ae8f917d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded726db-42f6-423a-92e9-73194685a2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3d12bef0-0338-45a0-836f-83be5ab150eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use name_matching from medium: https://medium.com/dnb-data-science-hub/company-name-matching-6a6330710334\n",
    "matcher = NameMatcher(top_n=3,\n",
    "    # lowercase=True,\n",
    "    punctuations=True,\n",
    "    # remove_ascii=True,\n",
    "    # legal_suffixes=False,\n",
    "    # common_words=False,\n",
    "    verbose=True)\n",
    "\n",
    "matcher.set_distance_metrics(['discounted_levenshtein',\n",
    "                              'SSK', \n",
    "                              'fuzzy_wuzzy_token_sort'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "fb460a99-c7b9-42e2-aa16-ee351f8be438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing...\n",
      "\n",
      "preprocessing complete \n",
      " searching for matches...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [03:11<00:00,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible matches found   \n",
      " fuzzy matching...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 199943/199943 [10:27<00:00, 318.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO - USE MATCHER ON UNIQUE NAMES ONLY\n",
    "matcher.load_and_process_master_data('preproc_recalling_firm', df_recall)\n",
    "matches = matcher.match_names(to_be_matched=df_device, column_matching='preproc_manufacturer_d_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c1e3761a-667b-4eb9-b1db-045681c1f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the dfs based on the matches\n",
    "combined = pd.merge(df_recall, matches, left_index=True, right_on='match_index')\n",
    "combined = pd.merge(combined, df_device, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "4b2daade-e94d-4a80-8217-313017f94553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_name</th>\n",
       "      <th>score</th>\n",
       "      <th>recalling_firm</th>\n",
       "      <th>preproc_recalling_firm</th>\n",
       "      <th>manufacturer_d_name</th>\n",
       "      <th>preproc_manufacturer_d_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40896</th>\n",
       "      <td>depuy orthopaedics</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Depuy Orthopaedics, Inc.</td>\n",
       "      <td>depuy orthopaedics</td>\n",
       "      <td>DEPUY ORTHOPAEDICS, INC.</td>\n",
       "      <td>depuy orthopaedics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40897</th>\n",
       "      <td>depuy orthopaedics</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Depuy Orthopaedics, Inc.</td>\n",
       "      <td>depuy orthopaedics</td>\n",
       "      <td>DEPUY ORTHOPAEDICS, INC.</td>\n",
       "      <td>depuy orthopaedics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110433</th>\n",
       "      <td>depuy orthopaedics</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Depuy Orthopaedics, Inc.</td>\n",
       "      <td>depuy orthopaedics</td>\n",
       "      <td>DEPUY ORTHOPAEDICS, INC.</td>\n",
       "      <td>depuy orthopaedics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110435</th>\n",
       "      <td>depuy orthopaedics</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Depuy Orthopaedics, Inc.</td>\n",
       "      <td>depuy orthopaedics</td>\n",
       "      <td>DEPUY ORTHOPAEDICS, INC.</td>\n",
       "      <td>depuy orthopaedics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9681</th>\n",
       "      <td>biomerieux</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Biomerieux Inc</td>\n",
       "      <td>biomerieux</td>\n",
       "      <td>BIOMÉRIEUX SA</td>\n",
       "      <td>biomerieux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166574</th>\n",
       "      <td>becton dickinson</td>\n",
       "      <td>88.527472</td>\n",
       "      <td>Becton Dickinson &amp; Co.</td>\n",
       "      <td>becton dickinson</td>\n",
       "      <td>BECTON DICKINSON AND CO.</td>\n",
       "      <td>becton dickinson and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174894</th>\n",
       "      <td>becton dickinson</td>\n",
       "      <td>88.527472</td>\n",
       "      <td>Becton Dickinson &amp; Co.</td>\n",
       "      <td>becton dickinson</td>\n",
       "      <td>BECTON DICKINSON AND CO.</td>\n",
       "      <td>becton dickinson and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174895</th>\n",
       "      <td>becton dickinson</td>\n",
       "      <td>88.527472</td>\n",
       "      <td>Becton Dickinson &amp; Co.</td>\n",
       "      <td>becton dickinson</td>\n",
       "      <td>BECTON DICKINSON AND CO.</td>\n",
       "      <td>becton dickinson and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177874</th>\n",
       "      <td>becton dickinson</td>\n",
       "      <td>88.527472</td>\n",
       "      <td>Becton Dickinson &amp; Co.</td>\n",
       "      <td>becton dickinson</td>\n",
       "      <td>BECTON DICKINSON AND CO.</td>\n",
       "      <td>becton dickinson and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177875</th>\n",
       "      <td>becton dickinson</td>\n",
       "      <td>88.527472</td>\n",
       "      <td>Becton Dickinson &amp; Co.</td>\n",
       "      <td>becton dickinson</td>\n",
       "      <td>BECTON DICKINSON AND CO.</td>\n",
       "      <td>becton dickinson and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118056 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                match_name       score            recalling_firm  \\\n",
       "40896   depuy orthopaedics  100.000000  Depuy Orthopaedics, Inc.   \n",
       "40897   depuy orthopaedics  100.000000  Depuy Orthopaedics, Inc.   \n",
       "110433  depuy orthopaedics  100.000000  Depuy Orthopaedics, Inc.   \n",
       "110435  depuy orthopaedics  100.000000  Depuy Orthopaedics, Inc.   \n",
       "9681            biomerieux  100.000000            Biomerieux Inc   \n",
       "...                    ...         ...                       ...   \n",
       "166574    becton dickinson   88.527472    Becton Dickinson & Co.   \n",
       "174894    becton dickinson   88.527472    Becton Dickinson & Co.   \n",
       "174895    becton dickinson   88.527472    Becton Dickinson & Co.   \n",
       "177874    becton dickinson   88.527472    Becton Dickinson & Co.   \n",
       "177875    becton dickinson   88.527472    Becton Dickinson & Co.   \n",
       "\n",
       "       preproc_recalling_firm       manufacturer_d_name  \\\n",
       "40896      depuy orthopaedics  DEPUY ORTHOPAEDICS, INC.   \n",
       "40897      depuy orthopaedics  DEPUY ORTHOPAEDICS, INC.   \n",
       "110433     depuy orthopaedics  DEPUY ORTHOPAEDICS, INC.   \n",
       "110435     depuy orthopaedics  DEPUY ORTHOPAEDICS, INC.   \n",
       "9681               biomerieux             BIOMÉRIEUX SA   \n",
       "...                       ...                       ...   \n",
       "166574       becton dickinson  BECTON DICKINSON AND CO.   \n",
       "174894       becton dickinson  BECTON DICKINSON AND CO.   \n",
       "174895       becton dickinson  BECTON DICKINSON AND CO.   \n",
       "177874       becton dickinson  BECTON DICKINSON AND CO.   \n",
       "177875       becton dickinson  BECTON DICKINSON AND CO.   \n",
       "\n",
       "       preproc_manufacturer_d_name  \n",
       "40896           depuy orthopaedics  \n",
       "40897           depuy orthopaedics  \n",
       "110433          depuy orthopaedics  \n",
       "110435          depuy orthopaedics  \n",
       "9681                    biomerieux  \n",
       "...                            ...  \n",
       "166574        becton dickinson and  \n",
       "174894        becton dickinson and  \n",
       "174895        becton dickinson and  \n",
       "177874        becton dickinson and  \n",
       "177875        becton dickinson and  \n",
       "\n",
       "[118056 rows x 6 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[combined['score'] > 80][['match_name', 'score', 'recalling_firm', 'preproc_recalling_firm', 'manufacturer_d_name', 'preproc_manufacturer_d_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f1e3103d-a06d-4cc5-96a4-b3c32aa59072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved objects successfully!\n"
     ]
    }
   ],
   "source": [
    "# IDEA - run this once and save as a df object\n",
    "import pickle\n",
    "try:\n",
    "    combined.to_pickle('combined_df.pkl')\n",
    "    # Save the model to a pickle file\n",
    "    with open('kmeans.pkl', 'wb') as file:\n",
    "        pickle.dump(kmeans, file)\n",
    "    print('saved objects successfully!')\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807943a8-ff47-4066-9d05-30753cfdf044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74776db2-d2e0-4f15-a116-fe7053d3db68",
   "metadata": {},
   "source": [
    "## cluster using similarity ratio\n",
    "Use SequenceMatcher on combined list of manufacturers to find similar groups. \n",
    "1. Combine dfs into two cols: [Recall/Event, 'Preproc Manufacturer Name'].\n",
    "2. Apply similarity ratios to group similar strings. Label by \"key\"\n",
    "\n",
    "\n",
    "<b>!! Has not run successfully !!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "11d3660f-9233-4c4e-89b8-537489d8da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from difflib import SequenceMatcher\n",
    "# from itertools import groupby\n",
    "\n",
    "# def group_similar_strings(strings, threshold=0.8):\n",
    "#     \"\"\"\n",
    "#     groups similar strings by using SequenceMatcher\n",
    "#     \"\"\"\n",
    "#     start = time.time()\n",
    "    \n",
    "#     def similarity_ratio(a, b):\n",
    "#         return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "#     sorted_strings = sorted(strings)\n",
    "\n",
    "#     # group by similarity to the first string in each group\n",
    "#     grouped_strings = {}\n",
    "#     for key, group in groupby(sorted_strings, lambda s: sorted([x for x in sorted_strings if similarity_ratio(s,x) >= threshold])[0]):\n",
    "#         grouped_strings[key] = list(group)\n",
    "\n",
    "#     print(f'------------ elapsed train time: {time.time() - start} seconds -------------')\n",
    "#     return grouped_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "247bc897-a92b-4de9-96cd-57fd3d8ce61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now we need to combine recall and event device manufacturers into one list before vectorizing\n",
    "# # input_names = set(df_recall['preproc_recalling_firm'])\n",
    "# # input_names.update(df_device['preproc_manufacturer_d_name'])\n",
    "# # print(len(input_names))\n",
    "\n",
    "# grouped_strings = group_similar_strings(input_names)\n",
    "# print(grouped_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76643db8-3738-492f-94a9-a019677162e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566054d-c2be-45bf-9381-6e4cf6ea793e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff778b-8c4f-45af-923c-16db34999ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
